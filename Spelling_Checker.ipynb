{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spelling Checker.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBvom7d2j1p8",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# Spelling Checker\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDCMEs3nkIgG",
        "colab_type": "text"
      },
      "source": [
        "***Motivation:*** Checking the spelling of words in the text is the most basic requirement in any text processing/analysis task. Thus, developing a simple language model that checks the correctness of the word's spelling and suggests possible alternatives is a good starting point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhD_dT6oiPfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import re #for regular expression\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrJdRmR2HKKn",
        "colab_type": "text"
      },
      "source": [
        "### Language Model P(c)\n",
        "---\n",
        "In a given text, we can find the probability of occurence of each word. \n",
        "\n",
        "Formally, P(c) gives the probability of word c appearing in the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeQOpGn_lVu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokens(text): \n",
        "  return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "def p(word, word_count):\n",
        "  total_words = sum(word_count.values()) \n",
        "  return word_count[word] / total_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLwX_08BJoMY",
        "colab_type": "text"
      },
      "source": [
        "After reading the file, we need to extract the words while ignoring punctuations, thus we make use of regular expression. The regex '\\w+' extracts alphanumeric as well as underscore strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "estEwdG5GuwP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "4bbf25db-6ef8-4472-8fb3-475feae363d4"
      },
      "source": [
        "words = Counter(tokens(open('sample.txt').read()))\n",
        "print(\"There are a total of \", sum(words.values()), ' words out of which ', len(words),\\\n",
        "      ' are unique words.')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are a total of  1115585  words out of which  32198  are unique words.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFHYcFG3Lc15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "6daf40e3-6225-4a62-f783-5a45b06c0d30"
      },
      "source": [
        "labels, values = zip(*words.most_common(10))\n",
        "\n",
        "indexes = np.arange(len(labels))\n",
        "\n",
        "plt.bar(indexes, values,)\n",
        "plt.xticks(indexes, labels)\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dcu-Ln9XOEci",
        "colab_type": "text"
      },
      "source": [
        "The most commmon word is 'the' appearing ~ 80k times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smD-wSY-OPeL",
        "colab_type": "text"
      },
      "source": [
        "### Candidate Model \n",
        "---\n",
        "Misspelled words often look similar to the correct word with a few errors such as missed characters, extra characters etc. The objective is to find the most likely spelling correct of a word w. Thus, we need to find correction c out of all candidate corrections such that it mazimizes the probability that c is the correction.\n",
        "\n",
        "These candidates are generated using the distance measure, edit distance to model the different type of spelling errors. Here, we use **simple edit** which deletes, transposes, replaces and insrts to generate candidate set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6LxzZM_YO2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simpleEdit(word):\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:] for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiQbiZlQZBDy",
        "colab_type": "text"
      },
      "source": [
        "The candidate set generated is usually very large as for each word there are 54n + 25 candidates, where n is the length of the word. There might be duplicates.\n",
        "\n",
        "For example, when w = 'doble', n = 4, thus, the upperbound on size of set is 295."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrR8g-zjZZ1c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "107f98dc-ef63-4a7f-c216-39535cc1e640"
      },
      "source": [
        "print(\"The length of the candidate set\", len(simpleEdit('doble')))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the candidate set 286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd8dkAT8ZZR-",
        "colab_type": "text"
      },
      "source": [
        "Now, a lot of the words generated in the candidate set won't be present in our dictionary, thus we can eliminate those to reduce the size of our candidate set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIrl5tpWaWhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "cf008f0d-0c76-4361-a5b5-a7dd847ca6d9"
      },
      "source": [
        "def known(words_list):\n",
        "  return(set(w for w in words_list if w in words ))\n",
        "\n",
        "known((simpleEdit('doble')))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dole', 'double', 'doyle', 'noble'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sxEN5ima04s",
        "colab_type": "text"
      },
      "source": [
        "In the primary generation of candidate, we used 1 distance difference. Now, lets increase the number of edits to **two simple edit**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v0AL6e1bBjO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def twoEdits(word):\n",
        "  return set([e2 for e1 in simpleEdit(word) for e2 in simpleEdit(e1)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYZhYU5PbQkY",
        "colab_type": "text"
      },
      "source": [
        "The length of this candidate set will be even larger but we will again use only those words which exist in our dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-WQAtOTbYHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        },
        "outputId": "90a7b7ae-4000-48b4-9a2a-0017bf70a89d"
      },
      "source": [
        "print(\"The length of the candidate set\", len(twoEdits('doble')))\n",
        "known(twoEdits('doble'))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the candidate set 36860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'able',\n",
              " 'amble',\n",
              " 'bible',\n",
              " 'cable',\n",
              " 'dale',\n",
              " 'diable',\n",
              " 'dobroe',\n",
              " 'dodge',\n",
              " 'doe',\n",
              " 'dole',\n",
              " 'doled',\n",
              " 'doles',\n",
              " 'doll',\n",
              " 'dolls',\n",
              " 'dome',\n",
              " 'done',\n",
              " 'donne',\n",
              " 'dose',\n",
              " 'double',\n",
              " 'doubled',\n",
              " 'doubles',\n",
              " 'doubly',\n",
              " 'doute',\n",
              " 'dove',\n",
              " 'doyle',\n",
              " 'doze',\n",
              " 'fable',\n",
              " 'gobble',\n",
              " 'hole',\n",
              " 'mobile',\n",
              " 'mole',\n",
              " 'molle',\n",
              " 'noble',\n",
              " 'nobler',\n",
              " 'nobles',\n",
              " 'ole',\n",
              " 'pole',\n",
              " 'robe',\n",
              " 'role',\n",
              " 'ruble',\n",
              " 'sable',\n",
              " 'sole',\n",
              " 'table'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTdvzFikcFN1",
        "colab_type": "text"
      },
      "source": [
        "### Error Model P(w|c)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdkdGmkUfK_i",
        "colab_type": "text"
      },
      "source": [
        "The error model states that smaller the edit distance, smaller the error. all known words with edit distance 1 are more probable than the those which are 2 edit distance away. However the highest priority is given to known word with 0 edit distance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk1J75_IdbIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correct(word): \n",
        "  candidates = known([word]) or known(simpleEdit(word)) or known(twoEdits(word)) or [word]\n",
        "  return max(candidates, key=words.get)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BILfP4Jafo9W",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FUohQrtgdRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "5cd3895f-9476-4b69-b53e-95ebbf86a6d9"
      },
      "source": [
        "list(map(correct, tokens('Speling errurs in somethink. Whutever; unusuel misteakes everyware?')))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['spelling',\n",
              " 'errors',\n",
              " 'in',\n",
              " 'something',\n",
              " 'whatever',\n",
              " 'unusual',\n",
              " 'mistakes',\n",
              " 'everywhere']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-BiJQ2Qnx5j",
        "colab_type": "text"
      },
      "source": [
        "We evaluate the performance of our model against a spelling error corpus. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTAU9gV9oqNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "49c87fba-af38-4071-a514-3bb49373d0ce"
      },
      "source": [
        "def spelltest(tests, verbose=False):\n",
        "    import time\n",
        "    start = time.clock()\n",
        "    good, unknown = 0, 0\n",
        "    n = len(tests)\n",
        "    for right, wrong in tests:\n",
        "        w = correction(wrong)\n",
        "        good += (w == right)\n",
        "        if w != right:\n",
        "            unknown += (right not in words)\n",
        "            if verbose:\n",
        "                print('correction({}) => {} ({}); expected {} ({})'\\\n",
        "                      .format(wrong, w, words[w], right, words[right]))\n",
        "    dt = time.clock() - start\n",
        "    print('{:.0%} of {} correct ({:.0%} unknown) at {:.0f} words per second '\\\n",
        "          .format(good / n, n, unknown / n, n / dt))\n",
        "    \n",
        "def Testset(lines):\n",
        "    return [(right, wrong)\n",
        "            for (right, wrongs) in (line.split(':') for line in lines)\n",
        "            for wrong in wrongs.split()]\n",
        "\n",
        "spelltest(Testset(open('test1.txt'))) # Development set\n",
        "spelltest(Testset(open('test2.txt'))) # Final test set\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75% of 270 correct at 40 words per second\n",
            "69% of 400 correct at 32 words per second\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}